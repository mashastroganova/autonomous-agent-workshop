{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "from typing_extensions import Annotated\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import autogen\n",
    "from autogen.cache import Cache\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST.json\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4o\", \"gpt4-turbo\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "settings = {\n",
    "    'host': os.environ.get('COSMOS_ENDPOINT'),\n",
    "    'master_key': os.environ.get('ACCOUNT_KEY'),\n",
    "    'database_id': os.environ.get('COSMOS_DATABASE'),\n",
    "    'container_id': os.environ.get('COSMOS_CONTAINER'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"config_list\": config_list, \"cache_seed\": 42}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    code_execution_config=False\n",
    ")\n",
    "planner = autogen.AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    system_message=\"Create a plan to troubleshoot the issue and solve the problem of the user.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "troubleshooter = autogen.AssistantAgent(\n",
    "    name=\"Troubleshooter\",\n",
    "    system_message=\"Identify the issue with the user's system based on the available data and provide a solution.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "data_engineer = autogen.AssistantAgent(\n",
    "    name=\"Data Engineer\",\n",
    "    system_message=\"Write the code to retrieve the needed data, summarize the data, and provide it to the troubleshooter.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, planner, troubleshooter, data_engineer], messages=[], max_round=15)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "from autogen.coding import DockerCommandLineCodeExecutor\n",
    "\n",
    "# Create a temporary directory to store the code files.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Create a Docker command line code executor.\n",
    "executor = DockerCommandLineCodeExecutor(\n",
    "    image=\"python:3.12-slim\",  # Execute code using the given docker image name.\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# Create an agent with code executor configuration that uses docker.\n",
    "code_executor_agent_using_docker = ConversableAgent(\n",
    "    \"code_executor_agent_docker\",\n",
    "    llm_config=False,  # Turn off LLM for this agent.\n",
    "    code_execution_config={\"executor\": executor},  # Use the docker command line code executor.\n",
    "    human_input_mode=\"ALWAYS\",  # Always take human input for this agent for safety.\n",
    ")\n",
    "\n",
    "# When the code executor is no longer used, stop it to release the resources.\n",
    "# executor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@user_proxy.register_for_execution()\n",
    "@executor.register_for_llm(name=\"python\", description=\"run cell in ipython and return the execution result.\")\n",
    "def exec_python(cell: Annotated[str, \"Valid Python cell to execute.\"]) -> str:\n",
    "    ipython = get_ipython()\n",
    "    result = ipython.run_cell(cell)\n",
    "    log = str(result.result)\n",
    "    if result.error_before_exec is not None:\n",
    "        log += f\"\\n{result.error_before_exec}\"\n",
    "    if result.error_in_exec is not None:\n",
    "        log += f\"\\n{result.error_in_exec}\"\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import azure.cosmos.documents as documents\n",
    "import azure.cosmos.cosmos_client as cosmos_client\n",
    "import azure.cosmos.exceptions as exceptions\n",
    "from azure.cosmos.partition_key import PartitionKey\n",
    "import json\n",
    "\n",
    "HOST = settings['host']\n",
    "MASTER_KEY = settings['master_key']\n",
    "DATABASE_ID = settings['database_id']\n",
    "CONTAINER_ID = settings['container_id']\n",
    "\n",
    "# Initialize the Cosmos client\n",
    "client = cosmos_client.CosmosClient(HOST, {'masterKey': MASTER_KEY})\n",
    "\n",
    "# Get the database and container\n",
    "db = client.get_database_client(DATABASE_ID)\n",
    "container = db.get_container_client(CONTAINER_ID)\n",
    "\n",
    "def get_customer_info(customer_id):\n",
    "    try:\n",
    "        # Query the container for the customer with the specified ID\n",
    "        query = f\"SELECT * FROM c WHERE c.id = '{customer_id}'\"\n",
    "        items = list(container.query_items(query=query, enable_cross_partition_query=True))\n",
    "        \n",
    "        if items:\n",
    "            # If the customer is found, return the customer information as JSON\n",
    "            customer_info = items[0]\n",
    "            return json.dumps(customer_info, default=str)\n",
    "        else:\n",
    "            # If the customer is not found, return an error message as JSON\n",
    "            error_message = {'error': f\"Customer with ID '{customer_id}' not found.\"}\n",
    "            return json.dumps(error_message)\n",
    "    \n",
    "    except exceptions.CosmosHttpResponseError as e:\n",
    "        # If there's an error querying the container, return the error message as JSON\n",
    "        error_message = {'error': str(e)}\n",
    "        return json.dumps(error_message)\n",
    "\n",
    "\n",
    "def get_outage_info(customer_address):\n",
    "    # Extract the city from the customer's address\n",
    "    city = customer_address.split(', ')[1]\n",
    "    \n",
    "    # Define the outage information for each city\n",
    "    outage_info = {\n",
    "        'New York': {\n",
    "            'status': 'outage',\n",
    "            'message': 'There is currently a mass outage in New York affecting multiple services.',\n",
    "            'affected_services': ['Internet', 'Phone', 'TV'],\n",
    "            'estimated_resolution_time': '2 days'\n",
    "        },\n",
    "        'Chicago': {\n",
    "            'status': 'healthy',\n",
    "            'message': 'All services are operating normally in Chicago.',\n",
    "            'affected_services': [],\n",
    "            'estimated_resolution_time': None\n",
    "        },\n",
    "        'San Francisco': {\n",
    "            'status': 'healthy',\n",
    "            'message': 'All services are operating normally in San Francisco.',\n",
    "            'affected_services': [],\n",
    "            'estimated_resolution_time': None\n",
    "        },\n",
    "        'Munich': {\n",
    "            'status': 'outage',\n",
    "            'message': 'There is currently a mass outage in Munich affecting Internet and Phone services.',\n",
    "            'affected_services': ['Internet', 'Phone'],\n",
    "            'estimated_resolution_time': '1 day'\n",
    "        },\n",
    "        'Berlin': {\n",
    "            'status': 'healthy',\n",
    "            'message': 'All services are operating normally in Berlin.',\n",
    "            'affected_services': [],\n",
    "            'estimated_resolution_time': None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Get the outage information for the customer's city\n",
    "    city_outage_info = outage_info.get(city)\n",
    "    \n",
    "    if city_outage_info:\n",
    "        # If the city is found, return the outage information as JSON\n",
    "        return json.dumps(city_outage_info)\n",
    "    else:\n",
    "        # If the city is not found, return a default message as JSON\n",
    "        default_message = {\n",
    "            'status': 'unknown',\n",
    "            'message': f\"No outage information available for {city}.\",\n",
    "            'affected_services': [],\n",
    "            'estimated_resolution_time': None\n",
    "        }\n",
    "        return json.dumps(default_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autogen.agentchat.register_function(\n",
    "    exec_python,\n",
    "    caller=chatbot,\n",
    "    executor=user_proxy,\n",
    "    name=\"sh\",\n",
    "    description=\"run a shell script and return the execution result.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager, message=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogenstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
